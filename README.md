# MalwareDetection

Main Notebook containing everything from data cleaning, feature engineering, LGBM implementation to kaggle submission is in MalwareDetection_ExploratoryTerritory.ipynb along with detailed instructions. 
<br>
It is recommended that the notebook is run in google colab with TPU as the hardware accelerator.
<br>
Link to notebook : https://colab.research.google.com/drive/1KkgpJfH5LvAtgoi2_H0Pr7Kjr5PaKab5
<br>
Link to video: https://www.youtube.com/watch?v=F_jVU_2fyn0&feature=youtu.be

<hr>


### Data sets
**Data source for train and test data**: [Kaggle link for Microsoft Malware Prediction](https://www.kaggle.com/c/microsoft-malware-prediction/data)
<br>


*   Each row in this dataset corresponds to a system, uniquely identified by a MachineIdentifier.
*   HasDetections is the target and indicates whether Malware was detected on the system.
*   HasDetections is missing in the test dataset and must be predicted using the train dataset.

**Data source for Antivirus Signature vs Timestamp** : [Kaggle link](https://www.kaggle.com/cdeotte/malware-timestamps)
<br>
This dataset consists of mappings from antivirus signature versions to timestamps. Antivirus signature version ('AvSigVersion') is updated approximately every 2 hours. 95\% of user antiviruses regularly update their antivirus signature version making them a trustworthy timestamp for each dataset observation. This means that the antivirus signature version of a system when it was sampled can be mapped to the time at which the system was sampled. The timestamps from this dataset are provided by Microsoft. Microsoft has derived these timestamps in the manner explained above, by approximating sampling time from 'AvSigVersion' of the observation.
<br>
<br>
**Pickled Objects** : [Kaggle link](https://www.kaggle.com/rachanaj/da-pickles)
<br>
train_df.pkl : Pickle of training data after preprocessing. <br>
test_df.pkl : Pickle of testing data after preprocessing. <br>
LGBMModel.pkl : Pickle of LGBM model after training. <br>

<hr>


**Feature Engineering and Dimensionality Reduction**

Feature engineering is done by feature.py

Additonally, notebook called "ExploratoryDataAnalysis.ipynb" provides data visualization along with contents of feature.py to back the feature choice and dropping.<br/>

To view the notebook on github use nbviewer as it gives proper rendering of plotly plots.<br/>

Alternatively, it is also hosted as private kernel at https://www.kaggle.com/mehulthakral/malware-detection-by-exploratory-territory <br/>

Steps to run :<br/>

1) Install all requirements numpy,matplotlib,pandas and seaborn (all are there in kaggle)
2) Additionally install chart_studio (from kaggle console in case of kaggle) for ploting plots using plotly.  
3) Change the path of the train.csv in "Loading the data" part use /kaggle/input/microsoft-malware-prediction/train.csv as path if using it in kaggle
4) Change path of the destination where the new_train.csv must be stored
<br/>
The new csv will have all the unwanted features removed.


Models Tried

1. LSTM : LSTM was tried. It is available in LSTM.py. The AUC was 0.55 approx
2. LSTM-CNN : Available in LSTM_CNN.py. results similar to LSTM were obtained
3. LightGBM : Testing

Observation : 

NeuralNets are not appropriate

<hr>

<h5> Time Series </h5>
This kind of malware risk detection is in essence a time series problem, with the sampling date of each data point greatly influencing the some of the system’s properties. The given dataset is also split into test and train in such a way that a majority of entries in the train data are from August and September 2018 while the training data is mostly
from October and November 2018.(As seen in LGBM_EDA.ipynb)
<br>
But the problems posed to the traditional time series approach by this dataset are the following:
<br>
• New systems are added to the dataset with time.
<br>
• There are systems that occasionally go offline for variable durations of time. No data from these systems are recorded in this period.
<br>
• Systems receive OS patches, bug fixes and OS upgrades over time thereby changing their properties. 
<br>
This analysis is intuitive as newer versions of operating systems and antivirus software to combat ever-improving malware.

<hr>

<h5> Light Gradient Boosting Machine </h5>
 <br>
 Given the shortcomings of having a plain time series perspective of the problem, it is best to have a final model that is not strictly a time-series approach to malware prediction, but can accommodate features that are indicative of time. Based on this there were two approaches we pursued: LSTM or Gradient boosting Decision Trees. To capture the time series aspect of the problem we engineer new features by making use of the Antivirus Signature vs Timestamp dataset.

Implementation of LGBM model along with detailed comments is in MalwareDetection_ExploratoryTerritory.ipynb

The LGBM model gives an AUC of 0.67 which is significantly better than LSTM's AUC of 0.50.
